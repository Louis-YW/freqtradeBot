{
  "id": "topic_5448822",
  "title": "JLR",
  "author": "JLR",
  "created_time": "April 14, 2023, 11:37:00 AM",
  "content": "G'dayThis is the hash value of my node blocks using 7 zip of all blocks from 0 - 3540, can you make sure yours are the same, it took roughly 30mins to hash the 440GB. a few years ago i had a full node and it was alot more than 440GB of blocks. i shall find the HDD and hash those blocks from 0-3540 and make sure there is no discrepancies Files: 3541Size: 473194525118 bytes (440 GiB)CRC32 checksum for data: 75CAE05B-000006EDCRC32 checksum for data and names: 7CC71966-00000707CRC64 checksum for data: 6C5F447189DAD881-000006E5CRC64 checksum for data and names: 411A0231D711287D-000006E5SHA256 checksum for data: 9ffe6bcb24a370ccfefc01912afbdcf0e1882fc55cb1921bdd783ecb0be54ddc-000006E8SHA256 checksum for data and names: f3998e5deaed78ee800ecae8f386e1a96de40001eee5887b8e78e7247b463fbb-000006F5SHA1 checksum for data: d801a27d17bf8bc9fd6ba2a649897c9803116a14-000006E7SHA1 checksum for data and names: 5cda9b11a506691d87e89e3e9264d2211a1837e1-000006E7BLAKE2sp checksum for data: 80b31ca446d1a2869734350f53249d5de4f707b829a73fe3afb9b091c8960254-000006F9BLAKE2sp checksum for data and names: 04a0d11bdd7f0fa09f2da360c7813b6871bb056c520427f584559253db48bc04-000006EA",
  "score": 0,
  "upvotes": 0,
  "downvotes": 0,
  "url": "https://bitcointalk.org/index.php?topic=5448822",
  "comments": [
    {
      "author": "ABCbits",
      "created_time": "April 14, 2023, 11:39:39 AM",
      "body": "Assuming you use Bitcoin Core to download Bitcoin blockchain, you should know Bitcoin Core doesn't always store block sequentially and it also store all stale/orphan block. That means hash of compressed blockchain between those who run Bitcoin Core would be different. And it's not the only technical reason why hash for each people who run full node is different.",
      "score": 0,
      "upvotes": 0,
      "downvotes": 0
    },
    {
      "author": "LoyceV",
      "created_time": "April 14, 2023, 05:50:07 PM",
      "body": "Quote from: JLR on April 14, 2023, 11:37:00 AMit took roughly 30mins to hash the 440GBWhy are you doing this? I don't see the point.Quotea few years ago i had a full node and it was alot more than 440GB of blocks.You must have it confused with something else. And my blocks directory is 502 GB now, 440 GB isn't enough.",
      "score": 0,
      "upvotes": 0,
      "downvotes": 0
    },
    {
      "author": "nc50lc",
      "created_time": "April 16, 2023, 05:50:29 AM",
      "body": "Quote from: JLR on April 14, 2023, 11:37:00 AM-snip- and make sure there is no discrepanciesYou node already did it while it's downloading the blockchain.It's making sure that the blocks that it downloaded have valid data;Furthermore, each block is liked with the previous block via its hash so if there's a discrepancy, it wont be able to reach the tip.But if you want to make sure that there's no discrepancies in your blockchain including the scripts:You may consider setting assumevalid=0 config or -assumevalid=0 command line optionThat will set your node to fully verify all the blocks starting from from the genesis block.Then use -reindex to validate your already downloaded blocks. (it will be slower than usual)",
      "score": 0,
      "upvotes": 0,
      "downvotes": 0
    }
  ]
}